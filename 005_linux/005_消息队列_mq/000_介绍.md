1. mq 消息 队列(消息中间件)
	1. activeMq
	2. rabbitMq
	3. activeMq
	4. zeroMq
	5. kafka
2. 减少服务与服务之间的调用,降低耦合度
3. 协议
	1. AMQP
		1. 高级消息队列协议（AMQP1）是一个异步消息传递所使用的应用层**协议**规范。
		2. AMQP客户端能够无视消息的来源任意发送和接受信息。
		3. 消息中间件的主要功能是消息的路由(Routing)和缓存(Buffering),在AMQP中提供类似功能的两种域模型：Exchange 和 Message 
		4.  AMQP 是语言中立的，而 JMS 仅和 Java 相关
# 比较 #
1. rabbitMq 
	1. 基于AMQP协议（Advanced Message Queue Protocol）
	2. 用 Erlang 实现的 MQ（Erlang消息机制与AMQP极度吻合）
2. activeMq
	1. 基于STOMP协议（注：我只知道是基于JMS api）


# ActiveMQ,RabbitMQ,ZeroMQ的比较 #
1. Tps(系统吞吐量,QPS（TPS）= 并发数/平均响应时间)
	1. ZeroMq 最好，RabbitMq 次之， ActiveMq 最差
2. 持久化消息
	1. zeroMq不支持，activeMq和rabbitMq都支持
3.  技术点：可靠性、灵活的路由、集群、事务、高可用的队列、消息排序、问题追踪、可视化管理工具、插件系统、社区 
	1. RabbitMq最好，ActiveMq次之，ZeroMq最差。 	
4. 高并发
	1. RabbitMQ最高，原因是它的实现语言是天生具备高并发高可用的erlang语言

# kafka和RabbitMQ的比较 #
1. RabbitMq比kafka成熟，在可用性上，稳定性上，可靠性上，RabbitMq超过kafka
2. Kafka设计的初衷就是处理日志的，可以看做是一个日志系统，针对性很强，所以它并没有具备一个成熟MQ应该具备的特性
3. Kafka的性能（吞吐量、tps）比RabbitMq要强



----------
# 消息丢失 #
https://www.jianshu.com/p/4491cba335d1
1. RabbitMQ 消息丢失
	1. 生产者弄丢了数据
		1. 可以选择用 RabbitMQ 提供的**事务功能**,就是生产者发送数据之前开启 RabbitMQ 事务channel.txSelect，然后发送消息，如果消息没有成功被 RabbitMQ 接收到，那么生产者会收到异常报错，此时就可以回滚事务channel.txRollback，然后重试发送消息；如果收到了消息，那么可以提交事务channel.txCommit
		2. 但是问题是，RabbitMQ 事务机制（同步）一搞，基本上吞吐量会下来，因为太耗性能
		3. 可以开启 **confirm** 模式，在生产者那里设置开启 confirm 模式之后，你每次写的消息都会分配一个唯一的 id，然后如果写入了 RabbitMQ 中，RabbitMQ 会给你回传一个 ack 消息，告诉你说这个消息 ok 了。如果 RabbitMQ 没能处理这个消息，会回调你的一个 nack 接口，告诉你这个消息接收失败，你可以重试。而且你可以结合这个机制自己在内存里维护每个消息 id 的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发

				事务机制是同步的，你提交一个事务之后会阻塞在那儿，但是 confirm 机制是异步的
	2. RabbitMQ 弄丢了数据
		1. 开启 RabbitMQ 的持久化
	3. 消费端弄丢了数据
		1. ack 机制 , 必须关闭 RabbitMQ 的自动 ack，可以通过一个 api 来调用就行

2. Kafka 消息丢失
	1. 生产者会不会弄丢数据
	2.  Kafka 弄丢了数据
		* 给 topic 设置 replication.factor 参数：这个值必须大于 1，要求每个 partition 必须有至少** 2 个副本**。
		* 在 Kafka 服务端设置 min.insync.replicas 参数：这个值必须大于 1，这个是要求一个 leader 至少感知到有至少一个 follower 还跟自己保持联系，没掉队，这样才能确保 leader 挂了还有一个 follower 吧。
		* 在 producer 端设置 acks=all：这个是要求每条数据，必须是写入所有 replica 之后，才能认为是写成功了。
		* 在 producer 端设置 retries=MAX（很大很大很大的一个值，无限次重试的意思）：这个是要求一旦写入失败，就无限重试，卡在这里了。
	3. 消费者
		1. 费者那边自动提交了 offset,让 Kafka 以为你已经消费好了这个消息
		2. 只要关闭自动提交 offset，在处理完之后自己手动提交 offset，就可以保证数据不会丢
		3. 但是此时确实还是可能会有重复消费，比如你刚处理完，还没提交 offset，结果自己挂了，此时肯定会重复消费一次，自己保证**幂等性**就好了




